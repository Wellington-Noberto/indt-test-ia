{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "00c63fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDT Developer test\n",
    "# Author: Wellington Noberto da Silva Araujo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba2008d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Wellington\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Wellington\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# NLP\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187a30f",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aec6622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Desafio-ML.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e54dab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2225 entries, 0 to 2224\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   category  2225 non-null   object\n",
      " 1   text      2225 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 34.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e49c8a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 duplicate rows removed\n"
     ]
    }
   ],
   "source": [
    "# Removing duplicate rows\n",
    "initial_number = df.shape[0]\n",
    "df = df.drop_duplicates(subset='text')\n",
    "final_number = df.shape[0]\n",
    "print('{} duplicate rows removed'.format(initial_number - final_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86f37349",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>worldcom boss  left books alone  former worldc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sport</td>\n",
       "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sport</td>\n",
       "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entertainment</td>\n",
       "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0           tech  tv future in the hands of viewers with home th...\n",
       "1       business  worldcom boss  left books alone  former worldc...\n",
       "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
       "3          sport  yeading face newcastle in fa cup premiership s...\n",
       "4  entertainment  ocean s twelve raids box office ocean s twelve..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92791b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            504\n",
       "business         503\n",
       "politics         403\n",
       "entertainment    369\n",
       "tech             347\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of classes\n",
    "num_classes = df.category.nunique()\n",
    "# Class names\n",
    "class_names = df.category.unique()\n",
    "# Checking if the classes are balanced\n",
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95584d39",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33946921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # remove ponctuations, special characters and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    # lower case the text\n",
    "    text = text.lower()\n",
    "    # create tokens, remove stop words and apply stemming\n",
    "    text = [stemmer.stem(word) for word in word_tokenize(text) if not word in set(stopwords.words('english'))]\n",
    "    \n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0e92165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['tokens'] = df.text.apply(process_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a700d",
   "metadata": {},
   "source": [
    "### Encoding tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fc51394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b6c22156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tokens in a text\n",
    "max_lenght = 50\n",
    "# List of tokens\n",
    "text_lists = df.tokens.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1b68fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode each token\n",
    "tokenizer = Tokenizer(num_words= None)\n",
    "tokenizer.fit_on_texts(text_lists)\n",
    "# Dictionary of encoded tokens\n",
    "word_index = tokenizer.word_index\n",
    "# Get arrays of encoded tokens\n",
    "text_sequences = tokenizer.texts_to_sequences(text_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a6d1ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of words\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9583985a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "text_padded = pad_sequences(text_sequences, maxlen= max_lenght, padding= 'post', truncating= 'post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc3c80",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6da81b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading GloVe Embedding\n",
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.100d.txt\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_dict[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "246a0f38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating an embedded matrix using only tokens used in our dataset\n",
    "max_embeddings = 100\n",
    "embedding_matrix = np.zeros((vocab_size, max_embeddings))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f8cf1",
   "metadata": {},
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "973cec44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12ae92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding the output labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "labels = df.category.values\n",
    "# Reshaping for one_hot_encoder function\n",
    "labels = np.reshape(labels, (len(labels), 1))\n",
    "# Encoding labels\n",
    "encoded_labels = one_hot_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1091214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a simple slicing method by selecting the first 70% of the data to the train and the rest for the test\n",
    "train_size = int(0.7 * len(text_padded))\n",
    "x_train, x_test = text_padded[:train_size], text_padded[train_size:]\n",
    "y_train, y_test = encoded_labels[:train_size], encoded_labels[train_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b13a8",
   "metadata": {},
   "source": [
    "### Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05845906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from keras.initializers import Constant\n",
    "from keras.losses import CategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72aacbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, max_embeddings, weights=[embedding_matrix], input_length=max_lenght, trainable=False))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation= 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7417e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656fdc4b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53458a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d690eae",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for test sequences \n",
    "pred = model.predict(x_test)\n",
    "# Get the higher output score\n",
    "pred_labels = np.argmax(pred, axis=-1)\n",
    "# Decoding the output labels\n",
    "y_pred = label_encoder.inverse_transform(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a92a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding the real values for testing \n",
    "y_true = label_encoder.inverse_transform(np.ravel(one_hot_encoder.inverse_transform(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18aabff",
   "metadata": {},
   "source": [
    "#### Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcfefd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(conf_matrix, cbar=False, cmap='Blues', xticklabels=class_names, yticklabels=class_names, annot=True, fmt='g')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b900b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing a classification report\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_ENV",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
